{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b76488-4c5f-4eb1-a175-c32e14e94f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T07:37:31.203749Z",
     "iopub.status.busy": "2024-11-12T07:37:31.203749Z",
     "iopub.status.idle": "2024-11-12T07:37:34.303469Z",
     "shell.execute_reply": "2024-11-12T07:37:34.303469Z",
     "shell.execute_reply.started": "2024-11-12T07:37:31.203749Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install geopandas metpy xarray[complete] -q\n",
    "!pip install eccodes cfgrib rioxarray ecmwf.opendata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94385330-0b94-458c-8208-d83f44687557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T07:40:52.720157Z",
     "iopub.status.busy": "2024-11-12T07:40:52.720157Z",
     "iopub.status.idle": "2024-11-12T07:40:54.619552Z",
     "shell.execute_reply": "2024-11-12T07:40:54.618550Z",
     "shell.execute_reply.started": "2024-11-12T07:40:52.720157Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cfgrib\n",
    "import os \n",
    "from ecmwf.opendata import Client\n",
    "# plt.style.available\n",
    "#import colormaps as cmaps \n",
    "import concurrent\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Disable warnings for data download via API\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "client = Client(source=\"ecmwf\")\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import cfgrib\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "from os import walk\n",
    "import netCDF4 as nc\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73172822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_l(data, fm):\n",
    "    try:\n",
    "        # Validate filename\n",
    "       \n",
    "        \n",
    "        # Convert data to dictionary\n",
    "        logging.info(\"Converting data to dictionary...\")\n",
    "        data_dict = data.squeeze().to_dict(data='list', encoding=False)\n",
    "        \n",
    "        # Helper function to recursively round numeric values\n",
    "        def round_numbers(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: round_numbers(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [round_numbers(item) for item in obj]\n",
    "            elif isinstance(obj, (float, np.float32, np.float64)):\n",
    "                return round(float(obj), 2)  # Round floats to 2 decimal places\n",
    "            elif isinstance(obj, (int, np.int32, np.int64)):\n",
    "                return int(obj)  # Keep integers as-is\n",
    "            else:\n",
    "                return obj  # Leave other types unchanged\n",
    "        \n",
    "        # Apply rounding to the dictionary\n",
    "        logging.info(\"Rounding numeric values to 2 decimal places...\")\n",
    "        rounded_data_dict = round_numbers(data_dict)\n",
    "        \n",
    "        # Helper function to handle non-serializable types\n",
    "        def convert_types(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_types(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_types(item) for item in obj]\n",
    "            elif isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "                return obj.isoformat()\n",
    "            elif isinstance(obj, timedelta):\n",
    "                return obj.total_seconds()\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.float32, np.float64)):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, (np.int32, np.int64)):\n",
    "                return int(obj)\n",
    "            raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "        \n",
    "        # Save to JSON file\n",
    "        file = os.path.join(os.getcwd(), f\"{fm}.json\")\n",
    "        logging.info(f\"Saving data to {file}...\")\n",
    "        with open(file, 'w') as json_file:\n",
    "            json.dump(rounded_data_dict, json_file, indent=4, default=convert_types)\n",
    "        \n",
    "        logging.info(\"Data successfully saved.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5733c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def dict_l(data,fm):\n",
    "#   data_dict=data.sel(longitude=slice(60, 100), latitude=slice(38, 0)).squeeze().to_dict(data='list', encoding=False)\n",
    "#   def convert_types(obj):\n",
    "#     if isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "#         return obj.isoformat()  # Convert datetime objects to ISO format\n",
    "#     elif isinstance(obj, timedelta):\n",
    "#         return obj.total_seconds()  # Convert timedelta to total seconds\n",
    "#     elif isinstance(obj, np.ndarray):\n",
    "#         return obj.tolist()  # Convert numpy arrays to lists\n",
    "#     elif isinstance(obj, (np.float32, np.float64)):\n",
    "#         return float(obj)  # Convert numpy floats to native floats\n",
    "#     elif isinstance(obj, (np.int32, np.int64)):\n",
    "#         return int(obj)  # Convert numpy integers to native ints\n",
    "#     raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "#   file=f\"{fm}.json\"\n",
    "#   # Save the dictionary as a JSON file with the extended convert_types function\n",
    "#   with open(file, 'w') as json_file:\n",
    "#       json.dump(data_dict, json_file, indent=4, default=convert_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a584e22-bddb-4933-8025-5617e7345164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:46:34.688071Z",
     "iopub.status.busy": "2024-11-12T05:46:34.688071Z",
     "iopub.status.idle": "2024-11-12T05:46:34.702078Z",
     "shell.execute_reply": "2024-11-12T05:46:34.702078Z",
     "shell.execute_reply.started": "2024-11-12T05:46:34.688071Z"
    }
   },
   "outputs": [],
   "source": [
    "# HRES:\n",
    "\n",
    "# fc: Forecast.\n",
    "# ENS:\n",
    "\n",
    "# cf: Control forecast.\n",
    "# pf: Perturbed forecast.\n",
    "# em: Ensemble mean.\n",
    "# es: Ensemble standard deviation.\n",
    "# ep: Probabilities.\n",
    "# Valid values for stream are:\n",
    "\n",
    "# oper: Atmospheric fields from HRES - 00 UTC and 12 UTC.\n",
    "# wave: Ocean wave fields from HRES - 00 UTC and 12 UTC.\n",
    "# enfo: Atmospheric fields from ENS.\n",
    "# waef: Ocean wave fields from ENS.\n",
    "# scda: Atmospheric fields from HRES - 06 UTC and 18 UTC.\n",
    "# scwv: Ocean wave fields from HRES - 06 UTC and 18 UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e9cd52-b894-4977-a4d4-221b089e93dc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-12T05:36:44.358208Z",
     "iopub.status.idle": "2024-11-12T05:36:44.358208Z",
     "shell.execute_reply": "2024-11-12T05:36:44.358208Z",
     "shell.execute_reply.started": "2024-11-12T05:36:44.358208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83011822416846379cb29f92a984153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<multiple>:   0%|          | 0.00/333M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m145\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m850\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43matms.grib2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ecmwf\\opendata\\client.py:147\u001b[0m, in \u001b[0;36mClient.retrieve\u001b[1;34m(self, request, target, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    146\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_urls(request, target\u001b[38;5;241m=\u001b[39mtarget, use_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 147\u001b[0m     result\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m \u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\downloader.py:111\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, target, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(url, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\base.py:129\u001b[0m, in \u001b[0;36mDownloaderBase.download\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar(\n\u001b[0;32m    124\u001b[0m     total\u001b[38;5;241m=\u001b[39msize,\n\u001b[0;32m    125\u001b[0m     initial\u001b[38;5;241m=\u001b[39mskip,\n\u001b[0;32m    126\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle(),\n\u001b[0;32m    127\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download, mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 129\u001b[0m         total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trust_size \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\multiurl.py:42\u001b[0m, in \u001b[0;36mMultiDownloader.transfer\u001b[1;34m(self, f, pbar)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, pbar):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m downloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownloaders:\n\u001b[1;32m---> 42\u001b[0m         \u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\http.py:133\u001b[0m, in \u001b[0;36mHTTPDownloaderBase.transfer\u001b[1;34m(self, f, pbar)\u001b[0m\n\u001b[0;32m    131\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    132\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_stream()\n\u001b[1;32m--> 133\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\http.py:448\u001b[0m, in \u001b[0;36mPartHTTPDownloader.make_stream.<locals>.iterate_requests\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m    437\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39missue_request(bytes_ranges)\n\u001b[0;32m    439\u001b[0m stream \u001b[38;5;241m=\u001b[39m DecodeMultipart(\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m    441\u001b[0m     request,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_headers,\n\u001b[0;32m    446\u001b[0m )\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m stream(chunk_size)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\multiurl\\multipart.py:164\u001b[0m, in \u001b[0;36mMultiPartStreamer.__call__\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m    163\u001b[0m         size \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m--> 164\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    167\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iter_content)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\site-packages\\urllib3\\response.py:1209\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   1211\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m )\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\site-packages\\urllib3\\response.py:1155\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# amt > self.chunk_left\u001b[39;00m\n\u001b[1;32m-> 1155\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\http\\client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\wrf_plot\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = list(range(3, 145, 3))\n",
    "\n",
    "client.retrieve(\n",
    "    time=0,\n",
    "    type=\"fc\",\n",
    "    stream='oper',step=step,\n",
    "    param=['d','gh',\"r\",\"vo\"],\n",
    "    levelist=[ 850, 500],\n",
    "    target=\"atms.grib2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_850=xr.open_dataset('atms.grib2',engine='cfgrib').sel(longitude=slice(60,100),latitude=slice(40,0),isobaricInhPa=850)\n",
    "ds_500=xr.open_dataset('atms.grib2',engine='cfgrib').sel(longitude=slice(60,100),latitude=slice(40,0),isobaricInhPa=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b220754",
   "metadata": {},
   "outputs": [],
   "source": [
    "gh8=ds_850['gh']\n",
    "d8=ds_850['d']\n",
    "r8=ds_850['r']\n",
    "vo8=ds_850['vo']\n",
    "\n",
    "dict_l(gh8,\"gh850\")\n",
    "dict_l(d8*1e5,\"div850\")\n",
    "dict_l(r8,\"rh850\")\n",
    "dict_l(vo8*1e5,\"vo850\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gh5=ds_500['gh']\n",
    "d5=ds_500['d']\n",
    "r5=ds_500['r']\n",
    "vo5=ds_500['vo']\n",
    "\n",
    "dict_l(gh5,\"gh500\")\n",
    "dict_l(d5*1e5,\"div500\")\n",
    "dict_l(r5,\"rh500\")\n",
    "dict_l(vo5*1e5,\"vo500\")\n",
    "\n",
    "ds_850.close()\n",
    "ds_500.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = list(range(3, 91, 3))\n",
    "\n",
    "\n",
    "client.retrieve(\n",
    "    time=0,\n",
    "    type=\"fc\",\n",
    "    stream='oper',step=step,\n",
    "    param=['tp','tcwv',\"msl\",\"2t\"],\n",
    "    target=\"atms.grib2\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1216be-6e81-4adb-b071-eca01b558cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T07:40:57.771959Z",
     "iopub.status.busy": "2024-11-12T07:40:57.771959Z",
     "iopub.status.idle": "2024-11-12T07:40:59.452275Z",
     "shell.execute_reply": "2024-11-12T07:40:59.451756Z",
     "shell.execute_reply.started": "2024-11-12T07:40:57.771959Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cfgrib\n",
    "t2 = xr.open_dataset('atms.grib2',engine='cfgrib',decode_coords=\"all\",\n",
    "                     backend_kwargs={ 'filter_by_keys':{ 'cfVarName': 't2m',}})['t2m']\n",
    "ds=xr.open_dataset('atms.grib2',engine='cfgrib')\n",
    "rf = ds.sel(longitude=slice(60,100),latitude=slice(40,0))['tp'][:, :, :]  # Select a specific time slice\n",
    "p =ds.sel(longitude=slice(60,100),latitude=slice(40,0))['msl'][:, :, :]/100  # Select a specific time slice\n",
    "tcw=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['tcwv']\n",
    "\n",
    "rf2=rf* units('m').to(units.mm)\n",
    "rf1=rf2.diff(dim='step').dropna(dim='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236af576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dict_l(data,fm):\n",
    "  data_dict=data.sel(longitude=slice(60, 100), latitude=slice(38, 0)).squeeze().to_dict(data='list', encoding=False)\n",
    "  def convert_types(obj):\n",
    "    if isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "        return obj.isoformat()  # Convert datetime objects to ISO format\n",
    "    elif isinstance(obj, timedelta):\n",
    "        return obj.total_seconds()  # Convert timedelta to total seconds\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert numpy arrays to lists\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)  # Convert numpy floats to native floats\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)  # Convert numpy integers to native ints\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "  file=f\"{fm}.json\"\n",
    "  # Save the dictionary as a JSON file with the extended convert_types function\n",
    "  with open(file, 'w') as json_file:\n",
    "      json.dump(data_dict, json_file, indent=4, default=convert_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def dict_c(data, fm, gdf):\n",
    "#     \"\"\"\n",
    "#     Clips the xarray DataArray to a specific region, converts it to a dictionary, and saves it as a JSON file.\n",
    "    \n",
    "#     Parameters:\n",
    "#     data (xarray.DataArray): The raster data to be clipped and converted to a dictionary.\n",
    "#     fm (str): The filename (without extension) to save the JSON file.\n",
    "#     gdf (geopandas.GeoDataFrame): The GeoDataFrame containing the shapefile for clipping.\n",
    "    \n",
    "#     Returns:\n",
    "#     None\n",
    "#     \"\"\"\n",
    "#     # Clip the data using the given GeoDataFrame (gdf)\n",
    "#     data = data.rio.write_crs(\"EPSG:4326\", inplace=True)  # Ensure CRS is correct\n",
    "#     if data.rio.crs != gdf.crs:\n",
    "#         gdf = gdf.to_crs(data.rio.crs)\n",
    "    \n",
    "#     clipped_data = data.rio.clip(gdf.geometry, gdf.crs, drop=True).squeeze()\n",
    "    \n",
    "#     # Convert the clipped data to a dictionary\n",
    "#     data_dict = clipped_data.fillna(0).to_dict(data='list', encoding=False)\n",
    "    \n",
    "\n",
    "#     # Function to handle non-serializable types\n",
    "#     def convert_types(obj):\n",
    "#         if isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "#             return obj.isoformat()  # Convert datetime objects to ISO format\n",
    "#         elif isinstance(obj, timedelta):\n",
    "#             return obj.total_seconds()  # Convert timedelta to total seconds\n",
    "#         elif isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()  # Convert numpy arrays to lists\n",
    "#         elif isinstance(obj, (np.float32, np.float64)):\n",
    "#             return float(obj)  # Convert numpy floats to native floats\n",
    "#         elif isinstance(obj, (np.int32, np.int64)):\n",
    "#             return int(obj)  # Convert numpy integers to native ints\n",
    "#         raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "    \n",
    "#     # Save the dictionary as a JSON file\n",
    "#     file = f\"{fm}_contour.json\"\n",
    "#     with open(file, 'w') as json_file:\n",
    "#         json.dump(data_dict, json_file, indent=4, default=convert_types)\n",
    "\n",
    "#     print(f\"Data successfully saved as {file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e43707",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_l(t2,\"2m_temp\")\n",
    "dict_l(rf2,\"rf\")\n",
    "dict_l(p,\"msl\")\n",
    "dict_l(tcw,\"tcwv\")\n",
    "# dict(w10,\"w10\")\n",
    "# dict(tcw,\"tcwv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ae95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_c(t2,\"2m_temp\",gdf)\n",
    "# dict_c(rf1,\"rf\",gdf)\n",
    "# dict_c(p,\"msl\",gdf)\n",
    "# dict_c(tcw,\"tcwv\",gdf)\n",
    "\n",
    "\n",
    "# cropped=t2.rio.write_crs(\"EPSG:4326\", inplace=True).rio.clip(gdf.geometry, gdf.crs, drop=True)\n",
    "# dfff=optomise_dataframe(cropped[0])\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# # If you're mapping directly from the grid:\n",
    "# cropped[16].plot(\n",
    "#     ax=ax,\n",
    "#     x='longitude',\n",
    "#     y='latitude',\n",
    "#     cmap='viridis',  # Choose a color map\n",
    "#     add_colorbar=True,\n",
    "#     robust=True,  # Removes extreme outliers\n",
    "# )\n",
    "# gdf.boundary.plot(ax=ax, color=\"black\", linewidth=0.5)\n",
    "# import plotly.express as px\n",
    "\n",
    "# df = px.data.gapminder().query(\"year==2007\")\n",
    "# fig = px.choropleth(df, locations=\"iso_alpha\",\n",
    "#                     color=\"lifeExp\", # lifeExp is a column of gapminder\n",
    "#                     hover_name=\"country\", # column to add to hover information\n",
    "#                     color_continuous_scale=px.colors.sequential.Plasma)\n",
    "# fig.show()\n",
    "\n",
    "# xr.open_dataset('atms.grib2',engine='cfgrib',backend_kwargs={ 'filter_by_keys':{ 'cfVarName': 'u10',}}).sel(longitude=slice(60,100),latitude=slice(40,0))['u10']\n",
    "\n",
    "\n",
    "# # Assuming `ds` is your xarray dataset\n",
    "# data_dict = ds['tp'].sel(longitude=slice(60, 100), latitude=slice(38, 0)).squeeze().to_dict(data='list', encoding=False)\n",
    "# # data_dict['tcw'] = ds['tcwv'].sel(longitude=slice(60, 100), latitude=slice(38, 0)).squeeze()\n",
    "# # Extended function to handle all types of non-serializable data\n",
    "# def convert_types(obj):\n",
    "#     if isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "#         return obj.isoformat()  # Convert datetime objects to ISO format\n",
    "#     elif isinstance(obj, timedelta):\n",
    "#         return obj.total_seconds()  # Convert timedelta to total seconds\n",
    "#     elif isinstance(obj, np.ndarray):\n",
    "#         return obj.tolist()  # Convert numpy arrays to lists\n",
    "#     elif isinstance(obj, (np.float32, np.float64)):\n",
    "#         return float(obj)  # Convert numpy floats to native floats\n",
    "#     elif isinstance(obj, (np.int32, np.int64)):\n",
    "#         return int(obj)  # Convert numpy integers to native ints\n",
    "#     raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "# # Save the dictionary as a JSON file with the extended convert_types function\n",
    "# with open('rf.json', 'w') as json_file:\n",
    "#     json.dump(data_dict, json_file, indent=4, default=convert_types)\n",
    "\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(12,12)) # Define the figure and specify size\n",
    "# ax = plt.subplot(1,1,1, projection=ccrs.PlateCarree()) # Specify plot area & projection\n",
    "# gl = ax.gridlines(draw_labels=True,linewidth=.6, color='gray', alpha=0.5, linestyle='-.')\n",
    "# gl.xlabel_style = {\"size\" : 6}\n",
    "# gl.top_labels = False\n",
    "# gl.right_labels = False\n",
    "# gl.ylabel_style = {\"size\" : 6}\n",
    "# va=rf[11,:,:]\n",
    "# # ax.set_title(f'AOD at 550nm, {str(da.forecast_reference_time[0].values)[:-16]}', fontsize=12) # Set figure title\n",
    "# ax.coastlines(color='black') # Add coastlines\n",
    "# im = plt.pcolormesh(va.longitude, va.latitude, va, cmap=cmaps.precip2_17lev\t, ) # Plot the data\n",
    "# # plt.contour(da.longitude, da.latitude, va ) # Plot the data\n",
    "# im.axes.add_feature(od)\n",
    "\n",
    "# lab=f'Total precipitation of at least 25 mm (%)'\n",
    "# cbar = plt.colorbar(im,fraction=0.021,shrink=0.85, pad=0.12,extend='min') # Specify the colourbar\n",
    "# # cbar.set_label(label='pressure(hPa)', size='large', weight='bold')\n",
    "# # plt.plot(mm[:8], nn[:8], color='m', linewidth=2, transform=ccrs.PlateCarree())  # Line connecting points\n",
    "# ax.set_xlim(60,100)\n",
    "# ax.set_ylim(6,38)\n",
    "\n",
    "# # plt.title(f\"Total precipitation of at least 25 mm (%) ,{va.valid_time.dt.strftime('%d-%B-%Y %H:%M').values}\")\n",
    "# ax.text(1.1, -0.012, '@Subhrajit', transform=ax.transAxes, fontsize=12,\n",
    "#             verticalalignment='bottom', bbox=dict(facecolor='white', alpha=0.8),weight='bold')\n",
    "# # time=va.valid_time.dt.strftime('%d_%B_%Y_%H').values\n",
    "# plt.grid(True)\n",
    "# # plt.scatter(x=mm[:8], y=nn[:8],\n",
    "# #             color=\"m\",\n",
    "# #             s=10,\n",
    "# #             alpha=1,\n",
    "# #             transform=ccrs.PlateCarree())\n",
    "\n",
    "# # for i, (lon, lat) in enumerate(zip(mm[:10], nn[:10]),):\n",
    "# #     plt.text(lon+1, lat, f'({lon}, {lat})', fontsize=12, ha='right', color='g',transform=ccrs.PlateCarree())\n",
    "    \n",
    "# # Show the plot with a frame\n",
    "# plt.gca().spines['top'].set_visible(True)\n",
    "# plt.gca().spines['right'].set_visible(True)\n",
    "# plt.gca().spines['left'].set_visible(True)\n",
    "# plt.gca().spines['bottom'].set_visible(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # cbar.set_label(lab) # Define the colourbar label\n",
    "# def animate(i):\n",
    "#     array = rf[i,:,:].values\n",
    "#     # array1 = p[i,:,:].values\n",
    "#     im.set_array(array1.flatten())\n",
    "#     # ax.set_title(f'AOD at 550nm')#, {str(da.forecast_reference_time[i].values)[:-16]}', fontsize=12)\n",
    "#     ax.set_title(f\"{p.valid_time[i].dt.strftime('%d-%B-%Y %H:%M').values}\",fontsize=12,weight='bold')\n",
    "\n",
    "\n",
    "# frames =16\n",
    "# ani = animation.FuncAnimation(fig, animate, frames, interval=150)\n",
    "# # ani.save('pressure.gif',fps = 90)\n",
    "# HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
