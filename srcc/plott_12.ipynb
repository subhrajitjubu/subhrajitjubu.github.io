{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi numpy urllib3  pandas datetime xarray[complete] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "# plt.style.available\n",
    "#import colormaps as cmaps \n",
    "#import concurrent\n",
    "import numpy as np\n",
    "# # Libraries to assist with animation and visualisations\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Disable warnings for data download via API\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "# import cfgrib\n",
    "# import eccodes\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "import zipfile\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import cdsapi\n",
    "URL = 'https://ads.atmosphere.copernicus.eu/api'\n",
    "KEY = '87bb8d36-2458-48c2-b5e3-f1fd352291bc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def dict_l(data, fm):\n",
    "    try:\n",
    "        # Validate filename\n",
    "       \n",
    "        \n",
    "        # Convert data to dictionary\n",
    "        data_dict = data.squeeze().to_dict(data='list', encoding=False)\n",
    "        \n",
    "        # Helper function to recursively round numeric values\n",
    "        def round_numbers(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: round_numbers(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [round_numbers(item) for item in obj]\n",
    "            elif isinstance(obj, (float, np.float32, np.float64)):\n",
    "                return round(float(obj), 2)  # Round floats to 2 decimal places\n",
    "            elif isinstance(obj, (int, np.int32, np.int64)):\n",
    "                return int(obj)  # Keep integers as-is\n",
    "            else:\n",
    "                return obj  # Leave other types unchanged\n",
    "        \n",
    "        # Apply rounding to the dictionary\n",
    "        rounded_data_dict = round_numbers(data_dict)\n",
    "        \n",
    "        # Helper function to handle non-serializable types\n",
    "        def convert_types(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_types(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_types(item) for item in obj]\n",
    "            elif isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "                return obj.isoformat()\n",
    "            elif isinstance(obj, timedelta):\n",
    "                return obj.total_seconds()\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.float32, np.float64)):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, (np.int32, np.int64)):\n",
    "                return int(obj)\n",
    "            raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "        \n",
    "        # Save to JSON file\n",
    "        file = os.path.join(os.getcwd(), f\"{fm}.json\")\n",
    "        with open(file, 'w') as json_file:\n",
    "            json.dump(rounded_data_dict, json_file, indent=4, default=convert_types)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-27'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date,timedelta\n",
    "time1=(date.today()- timedelta(days = 1)).strftime(\"%Y-%m-%d\")\n",
    "time1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = \"cams-global-atmospheric-composition-forecasts\"\n",
    "lead= [str(i) for i in range(0,73)]\n",
    "\n",
    "request = {\n",
    "    \"date\": [f\"{time1}/{time1}\"],\n",
    "    \"time\": [\"12:00\"],\n",
    "    \"leadtime_hour\": lead,\n",
    "    \"type\": [\"forecast\"],\n",
    "    \"data_format\": \"netcdf_zip\",\n",
    "    \"variable\": [\n",
    "         \"2m_dewpoint_temperature\",\n",
    "        \"dust_aerosol_optical_depth_550nm\",\n",
    "        \"mean_sea_level_pressure\",\n",
    "        \"nitrate_aerosol_optical_depth_550nm\",\n",
    "        \"particulate_matter_2.5um\",\n",
    "        \"particulate_matter_10um\",\n",
    "        \"sea_salt_aerosol_optical_depth_550nm\",\n",
    "        \"sulphate_aerosol_optical_depth_550nm\",\n",
    "        \"total_aerosol_optical_depth_550nm\",\n",
    "        \"convective_precipitation\",\n",
    "        \"high_cloud_cover\",\n",
    "        \"low_cloud_cover\",\n",
    "        \"medium_cloud_cover\",\n",
    "        \"total_cloud_cover\",\n",
    "        \"most_unstable_convective_available_potential_energy\",\n",
    "        \"most_unstable_convective_inhibition\"\n",
    "\n",
    "    ],\n",
    "    \"area\": [50, 50, 0, 100]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client(url=URL, key=KEY)\n",
    "client.retrieve(dataset, request).download('test.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ZipFile(\"test.zip\", 'r') as zObject: \n",
    "    zObject.extractall(path=\"./extracted_files\")  # Specify a different path for extraction\n",
    "\n",
    "ds1 = xr.open_dataset('./extracted_files/data_sfc.nc')  # Update the path to the extracted file\n",
    "os.rm('test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original time length: 73\n",
      "New time1 length: 73\n"
     ]
    }
   ],
   "source": [
    "ds=ds1.copy(deep=True)\n",
    "# Given information\n",
    "forecast_ref_time = ds['forecast_reference_time'].values\n",
    "hours=len(ds['forecast_period'])  # Number of forecast periods\n",
    "\n",
    "if isinstance(forecast_ref_time, (np.ndarray, xr.DataArray)):\n",
    "    forecast_ref_time = forecast_ref_time.item()  # or forecast_ref_time[0]\n",
    "\n",
    "# Convert to datetime if it's numpy datetime64\n",
    "forecast_ref_time = pd.to_datetime(forecast_ref_time)\n",
    "\n",
    "\n",
    "\n",
    "valid_time = pd.date_range(start=forecast_ref_time,  periods=hours,  # 100 hours = 100 steps\n",
    "    freq='1h'     # '1H' = 1-hour frequency\n",
    ")\n",
    "\n",
    "# Verify the length matches your existing time dimension\n",
    "print(f\"Original time length: {len(ds['forecast_period'])}\")\n",
    "print(f\"New time1 length: {len(valid_time)}\")\n",
    "\n",
    "# Assign the new coordinate to your dataset\n",
    "ds = ds.assign_coords(valid_time=('forecast_period', valid_time))\n",
    "\n",
    "# Now you can filter for JJAS months using the new time coordinate\n",
    "\n",
    "# If you want to make time1 the main dimension coordinate:\n",
    "ds = ds.swap_dims({'forecast_period': 'valid_time'})\n",
    "ds = ds.drop_vars('forecast_period')  # optional - remove the old time coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aod_du=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['duaod550']\n",
    "aod_ss=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['ssaod550']\n",
    "aod_su=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['suaod550']\n",
    "aod=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['aod550']\n",
    "aod_ni=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['niaod550']\n",
    "time=ds.valid_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pm25=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['pm2p5']\n",
    "pm10=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['pm10']\n",
    "\n",
    "lcc=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['lcc']\n",
    "mcc=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['mcc']\n",
    "hcc=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['hcc']\n",
    "tcc=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['tcc']\n",
    "\n",
    "cape=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['mucape']\n",
    "cin=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['mucin']\n",
    "\n",
    "d2m=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['d2m']\n",
    "cp=ds.sel(longitude=slice(50,100),latitude=slice(40,0))['cp']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " dict_l(1e9*pm25,\"PM25\")\n",
    " dict_l(1e9*pm10,\"PM10\")\n",
    "\n",
    " dict_l(lcc,\"LCC\")\n",
    " dict_l(mcc,\"MCC\")\n",
    " dict_l(hcc,\"HCC\")\n",
    " dict_l(tcc,\"TCC\")\n",
    "\n",
    " dict_l(cape,\"CAPE\")\n",
    " dict_l(cin,\"CIN\")\n",
    " dict_l(d2m-273.15,\"D2M\")\n",
    " dict_l(cp*1000,\"CP\")\n",
    "\n",
    " dict_l(aod_ss,\"AOD_SEA\")\n",
    " dict_l(aod_su,\"AOD_SUL\")\n",
    " dict_l(aod_ni,\"AOD_NIT\")\n",
    " dict_l(aod_du,\"AOD_DUST\")\n",
    " dict_l(aod,\"AOD_TOT\")\n",
    "\n",
    "dict_l(time,\"TIME\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Define the colors in RGBA format\n",
    "# colors = {\n",
    "#     \"blue\": (0, 0, 255, 1),\n",
    "#     \"aqua\": (0, 255, 255, 1),\n",
    "#     \"green\": (0, 255, 0, 1),\n",
    "#     \"yellow\": (255, 255, 0, 1),\n",
    "#     \"orange\": (255, 165, 0, 1),\n",
    "#     \"red\": (255, 0, 0, 1)\n",
    "# }\n",
    "\n",
    "# # Define color stops and corresponding positions\n",
    "# color_stops = [\n",
    "#     (0.0, (0, 0, 0, 1)),  # Changed to tuple\n",
    "#     (0.12, (0, 0, 255, 1)),  # Changed to tuple\n",
    "#     (0.25, (0, 255, 255, 1)),  # Changed to tuple\n",
    "#     (0.38, (0, 255, 0, 1)),  # Changed to tuple\n",
    "#     (0.5, (255, 255, 0, 1)),  # Changed to tuple\n",
    "#     (0.62, (255, 165, 0, 1)),  # Changed to tuple\n",
    "#     (0.75, (255, 0, 0, 1)),  # Changed to tuple\n",
    "#     (0.88, (238, 130, 238, 1)),  # Changed to tuple\n",
    "#     (1.0, (255, 255, 255, 1))  # Changed to tuple\n",
    "# ]\n",
    "\n",
    "# # Generate 100 interpolated values\n",
    "# n_points = 200\n",
    "# interpolated_colors = []\n",
    "\n",
    "# for i in range(n_points):\n",
    "#     pos = i / (n_points - 1)\n",
    "#     # Find the two closest stops\n",
    "#     for j in range(len(color_stops) - 1):\n",
    "#         if color_stops[j][0] <= pos <= color_stops[j + 1][0]:\n",
    "#             # Interpolate between the two stops\n",
    "#             start_pos, start_color = color_stops[j]\n",
    "#             end_pos, end_color = color_stops[j + 1]\n",
    "#             ratio = (pos - start_pos) / (end_pos - start_pos)\n",
    "#             interpolated_color = tuple(\n",
    "#                 int(start_color[k] + ratio * (end_color[k] - start_color[k])) if k < 3 else start_color[k]\n",
    "#                 for k in range(4)\n",
    "#             )\n",
    "#             rgba_string = f\"rgba({interpolated_color[0]}, {interpolated_color[1]}, {interpolated_color[2]}, {interpolated_color[3]})\"\n",
    "#             interpolated_colors.append([round(pos, 2), rgba_string])\n",
    "#             break\n",
    "\n",
    "# interpolated_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of interpolated colors\n",
    "# n_points = 256\n",
    "\n",
    "# # Prepare an empty list for the AMWG256 colormap\n",
    "# amwg256 = []\n",
    "\n",
    "# # Define the positions of the input colors in the sequence\n",
    "# color_positions = [i / (len(color_sequence) - 1) for i in range(len(color_sequence))]\n",
    "\n",
    "# # Generate interpolated colors for 256 points\n",
    "# for i in range(n_points):\n",
    "#     pos = i / (n_points - 1)\n",
    "#     # Find the two closest positions in the sequence\n",
    "#     for j in range(len(color_positions) - 1):\n",
    "#         if color_positions[j] <= pos <= color_positions[j + 1]:\n",
    "#             # Interpolate between the two colors\n",
    "#             start_pos, end_pos = color_positions[j], color_positions[j + 1]\n",
    "#             start_color, end_color = color_map[color_sequence[j]], color_map[color_sequence[j + 1]]\n",
    "#             ratio = (pos - start_pos) / (end_pos - start_pos)\n",
    "#             interpolated_color = tuple(\n",
    "#                 int(start_color[k] + ratio * (end_color[k] - start_color[k])) if k < 3 else start_color[k]\n",
    "#                 for k in range(4)\n",
    "#             )\n",
    "#             rgba_string = f\"rgba({interpolated_color[0]}, {interpolated_color[1]}, {interpolated_color[2]}, {interpolated_color[3]})\"\n",
    "#             amwg256.append([round(pos, 3), rgba_string])\n",
    "#             break\n",
    "\n",
    "# amwg256  # Display the first 10 color stops to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the colormap structure for GMT_panoply with stops: Black, Blue, Aqua, Green, Yellow, Orange, Red, White\n",
    "# gmt_color_sequence = [\"Bk\", \"Bl\", \"Aq\", \"Gr\", \"Ye\", \"Or\", \"Re\", \"Wh\"]\n",
    "\n",
    "# # Define the positions of the input colors\n",
    "# gmt_positions = [i / (len(gmt_color_sequence) - 1) for i in range(len(gmt_color_sequence))]\n",
    "\n",
    "# # Interpolating 256 colors for the GMT_panoply colormap\n",
    "# gmt_panoply_256 = []\n",
    "\n",
    "# for i in range(n_points):\n",
    "#     pos = i / (n_points - 1)\n",
    "#     # Find the two closest positions in the sequence\n",
    "#     for j in range(len(gmt_positions) - 1):\n",
    "#         if gmt_positions[j] <= pos <= gmt_positions[j + 1]:\n",
    "#             # Interpolate between the two colors\n",
    "#             start_pos, end_pos = gmt_positions[j], gmt_positions[j + 1]\n",
    "#             start_color, end_color = color_map[gmt_color_sequence[j]], color_map[gmt_color_sequence[j + 1]]\n",
    "#             ratio = (pos - start_pos) / (end_pos - start_pos)\n",
    "#             interpolated_color = tuple(\n",
    "#                 int(start_color[k] + ratio * (end_color[k] - start_color[k])) if k < 3 else start_color[k]\n",
    "#                 for k in range(4)\n",
    "#             )\n",
    "#             rgba_string = f\"rgba({interpolated_color[0]}, {interpolated_color[1]}, {interpolated_color[2]}, {interpolated_color[3]})\"\n",
    "#             gmt_panoply_256.append([round(pos, 3), rgba_string])\n",
    "#             break\n",
    "\n",
    "# gmt_panoply_256  # Display the first 10 color stops to verify\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
