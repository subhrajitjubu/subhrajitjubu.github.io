{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi numpy urllib3  pandas datetime xarray[complete] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "# plt.style.available\n",
    "#import colormaps as cmaps \n",
    "#import concurrent\n",
    "import numpy as np\n",
    "# # Libraries to assist with animation and visualisations\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Disable warnings for data download via API\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "# import cfgrib\n",
    "# import eccodes\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "import zipfile\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import cdsapi\n",
    "URL = 'https://ads.atmosphere.copernicus.eu/api'\n",
    "KEY = '87bb8d36-2458-48c2-b5e3-f1fd352291bc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def dict_l(data, fm):\n",
    "    try:\n",
    "        # Validate filename\n",
    "       \n",
    "        \n",
    "        # Convert data to dictionary\n",
    "        logging.info(\"Converting data to dictionary...\")\n",
    "        data_dict = data.squeeze().to_dict(data='list', encoding=False)\n",
    "        \n",
    "        # Helper function to recursively round numeric values\n",
    "        def round_numbers(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: round_numbers(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [round_numbers(item) for item in obj]\n",
    "            elif isinstance(obj, (float, np.float32, np.float64)):\n",
    "                return round(float(obj), 2)  # Round floats to 2 decimal places\n",
    "            elif isinstance(obj, (int, np.int32, np.int64)):\n",
    "                return int(obj)  # Keep integers as-is\n",
    "            else:\n",
    "                return obj  # Leave other types unchanged\n",
    "        \n",
    "        # Apply rounding to the dictionary\n",
    "        logging.info(\"Rounding numeric values to 2 decimal places...\")\n",
    "        rounded_data_dict = round_numbers(data_dict)\n",
    "        \n",
    "        # Helper function to handle non-serializable types\n",
    "        def convert_types(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_types(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_types(item) for item in obj]\n",
    "            elif isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "                return obj.isoformat()\n",
    "            elif isinstance(obj, timedelta):\n",
    "                return obj.total_seconds()\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.float32, np.float64)):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, (np.int32, np.int64)):\n",
    "                return int(obj)\n",
    "            raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "        \n",
    "        # Save to JSON file\n",
    "        file = os.path.join(os.getcwd(), f\"{fm}.json\")\n",
    "        logging.info(f\"Saving data to {file}...\")\n",
    "        with open(file, 'w') as json_file:\n",
    "            json.dump(rounded_data_dict, json_file, indent=4, default=convert_types)\n",
    "        \n",
    "        logging.info(\"Data successfully saved.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-02-28'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date,timedelta\n",
    "time1=(date.today()).strftime(\"%Y-%m-%d\")\n",
    "time1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 18:40:31,205 INFO [2024-09-26T00:00:00] Watch our [Forum]( https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "INFO:datapi.legacy_api_client:[2024-09-26T00:00:00] Watch our [Forum]( https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-02-28 18:40:32,193 INFO Request ID is ab136b5c-2b7c-40e7-9b13-28d009e33916\n",
      "INFO:datapi.legacy_api_client:Request ID is ab136b5c-2b7c-40e7-9b13-28d009e33916\n",
      "2025-02-28 18:40:32,406 INFO status has been updated to accepted\n",
      "INFO:datapi.legacy_api_client:status has been updated to accepted\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = \"cams-global-atmospheric-composition-forecasts\"\n",
    "lead= [str(i) for i in range(0,73)]\n",
    "\n",
    "request = {\n",
    "    \"date\": [f\"{time1}/{time1}\"],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"leadtime_hour\": lead,\n",
    "    \"type\": [\"forecast\"],\n",
    "    \"data_format\": \"netcdf_zip\",\n",
    "    \"variable\": [\n",
    "         \"2m_dewpoint_temperature\",\n",
    "        \"dust_aerosol_optical_depth_550nm\",\n",
    "        \"mean_sea_level_pressure\",\n",
    "        \"nitrate_aerosol_optical_depth_560nm\",\n",
    "        \"particulate_matter_2.5um\",\n",
    "        \"particulate_matter_10um\",\n",
    "        \"sea_salt_aerosol_optical_depth_550nm\",\n",
    "        \"sulphate_aerosol_optical_depth_550nm\",\n",
    "        \"total_aerosol_optical_depth_550nm\",\n",
    "        \"total_column_water_vapour\",\n",
    "        \"convective_precipitation\",\n",
    "        \"high_cloud_cover\",\n",
    "        \"low_cloud_cover\",\n",
    "        \"medium_cloud_cover\",\n",
    "        \"total_cloud_cover\",\n",
    "        \"most_unstable_convective_available_potential_energy\",\n",
    "        \"most_unstable_convective_inhibition\"\n",
    "\n",
    "    ],\n",
    "    \"area\": [60, 60, 0, 100]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client(url=URL, key=KEY)\n",
    "client.retrieve(dataset, request).download('test.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive E is New Volume\n",
      " Volume Serial Number is 1C64-8838\n",
      "\n",
      " Directory of e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"test.zip\", 'r') as zObject: \n",
    "    zObject.extractall(path=\".\")  # Specify a different path for extraction\n",
    "\n",
    "ds = xr.open_dataset('data_sfc.nc')  # Update the path to the extracted file\n",
    "os.rm('test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2025-02-27T12:00:00.000000000', '2025-02-27T13:00:00.000000000',\n",
       "        '2025-02-27T14:00:00.000000000', '2025-02-27T15:00:00.000000000',\n",
       "        '2025-02-27T16:00:00.000000000', '2025-02-27T17:00:00.000000000',\n",
       "        '2025-02-27T18:00:00.000000000', '2025-02-27T19:00:00.000000000',\n",
       "        '2025-02-27T20:00:00.000000000', '2025-02-27T21:00:00.000000000',\n",
       "        '2025-02-27T22:00:00.000000000', '2025-02-27T23:00:00.000000000',\n",
       "        '2025-02-28T00:00:00.000000000', '2025-02-28T01:00:00.000000000',\n",
       "        '2025-02-28T02:00:00.000000000', '2025-02-28T03:00:00.000000000',\n",
       "        '2025-02-28T04:00:00.000000000', '2025-02-28T05:00:00.000000000',\n",
       "        '2025-02-28T06:00:00.000000000', '2025-02-28T07:00:00.000000000',\n",
       "        '2025-02-28T08:00:00.000000000', '2025-02-28T09:00:00.000000000',\n",
       "        '2025-02-28T10:00:00.000000000', '2025-02-28T11:00:00.000000000',\n",
       "        '2025-02-28T12:00:00.000000000', '2025-02-28T13:00:00.000000000',\n",
       "        '2025-02-28T14:00:00.000000000', '2025-02-28T15:00:00.000000000',\n",
       "        '2025-02-28T16:00:00.000000000', '2025-02-28T17:00:00.000000000',\n",
       "        '2025-02-28T18:00:00.000000000', '2025-02-28T19:00:00.000000000',\n",
       "        '2025-02-28T20:00:00.000000000', '2025-02-28T21:00:00.000000000',\n",
       "        '2025-02-28T22:00:00.000000000', '2025-02-28T23:00:00.000000000',\n",
       "        '2025-03-01T00:00:00.000000000', '2025-03-01T01:00:00.000000000',\n",
       "        '2025-03-01T02:00:00.000000000', '2025-03-01T03:00:00.000000000',\n",
       "        '2025-03-01T04:00:00.000000000', '2025-03-01T05:00:00.000000000',\n",
       "        '2025-03-01T06:00:00.000000000', '2025-03-01T07:00:00.000000000',\n",
       "        '2025-03-01T08:00:00.000000000', '2025-03-01T09:00:00.000000000',\n",
       "        '2025-03-01T10:00:00.000000000', '2025-03-01T11:00:00.000000000',\n",
       "        '2025-03-01T12:00:00.000000000', '2025-03-01T13:00:00.000000000',\n",
       "        '2025-03-01T14:00:00.000000000', '2025-03-01T15:00:00.000000000',\n",
       "        '2025-03-01T16:00:00.000000000', '2025-03-01T17:00:00.000000000',\n",
       "        '2025-03-01T18:00:00.000000000', '2025-03-01T19:00:00.000000000',\n",
       "        '2025-03-01T20:00:00.000000000', '2025-03-01T21:00:00.000000000',\n",
       "        '2025-03-01T22:00:00.000000000', '2025-03-01T23:00:00.000000000',\n",
       "        '2025-03-02T00:00:00.000000000', '2025-03-02T01:00:00.000000000',\n",
       "        '2025-03-02T02:00:00.000000000', '2025-03-02T03:00:00.000000000',\n",
       "        '2025-03-02T04:00:00.000000000', '2025-03-02T05:00:00.000000000',\n",
       "        '2025-03-02T06:00:00.000000000', '2025-03-02T07:00:00.000000000',\n",
       "        '2025-03-02T08:00:00.000000000', '2025-03-02T09:00:00.000000000',\n",
       "        '2025-03-02T10:00:00.000000000', '2025-03-02T11:00:00.000000000',\n",
       "        '2025-03-02T12:00:00.000000000', '2025-03-02T13:00:00.000000000',\n",
       "        '2025-03-02T14:00:00.000000000', '2025-03-02T15:00:00.000000000',\n",
       "        '2025-03-02T16:00:00.000000000', '2025-03-02T17:00:00.000000000',\n",
       "        '2025-03-02T18:00:00.000000000', '2025-03-02T19:00:00.000000000',\n",
       "        '2025-03-02T20:00:00.000000000', '2025-03-02T21:00:00.000000000',\n",
       "        '2025-03-02T22:00:00.000000000', '2025-03-02T23:00:00.000000000',\n",
       "        '2025-03-03T00:00:00.000000000', '2025-03-03T01:00:00.000000000',\n",
       "        '2025-03-03T02:00:00.000000000', '2025-03-03T03:00:00.000000000',\n",
       "        '2025-03-03T04:00:00.000000000', '2025-03-03T05:00:00.000000000',\n",
       "        '2025-03-03T06:00:00.000000000', '2025-03-03T07:00:00.000000000',\n",
       "        '2025-03-03T08:00:00.000000000', '2025-03-03T09:00:00.000000000',\n",
       "        '2025-03-03T10:00:00.000000000', '2025-03-03T11:00:00.000000000',\n",
       "        '2025-03-03T12:00:00.000000000', '2025-03-03T13:00:00.000000000',\n",
       "        '2025-03-03T14:00:00.000000000', '2025-03-03T15:00:00.000000000',\n",
       "        '2025-03-03T16:00:00.000000000', '2025-03-03T17:00:00.000000000',\n",
       "        '2025-03-03T18:00:00.000000000', '2025-03-03T19:00:00.000000000',\n",
       "        '2025-03-03T20:00:00.000000000', '2025-03-03T21:00:00.000000000',\n",
       "        '2025-03-03T22:00:00.000000000', '2025-03-03T23:00:00.000000000',\n",
       "        '2025-03-04T00:00:00.000000000', '2025-03-04T01:00:00.000000000',\n",
       "        '2025-03-04T02:00:00.000000000', '2025-03-04T03:00:00.000000000',\n",
       "        '2025-03-04T04:00:00.000000000', '2025-03-04T05:00:00.000000000',\n",
       "        '2025-03-04T06:00:00.000000000', '2025-03-04T07:00:00.000000000',\n",
       "        '2025-03-04T08:00:00.000000000', '2025-03-04T09:00:00.000000000',\n",
       "        '2025-03-04T10:00:00.000000000', '2025-03-04T11:00:00.000000000',\n",
       "        '2025-03-04T12:00:00.000000000']], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.valid_time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aod_du=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['duaod550']\n",
    "aod_ss=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['ssaod550']\n",
    "aod_su=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['suaod550']\n",
    "aod=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['aod550']\n",
    "aod_ni=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['niaod550']\n",
    "time=ds.valid_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pm25=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['pm2p5']\n",
    "pm10=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['pm10']\n",
    "\n",
    "lcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['lcc']\n",
    "mcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mcc']\n",
    "hcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['hcc']\n",
    "tcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['tcc']\n",
    "\n",
    "cape=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mucape']\n",
    "cin=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mucin']\n",
    "\n",
    "d2m=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['d2m']\n",
    "cp=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['cp']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\PM25.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\PM10.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\LCC.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\MCC.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\HCC.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\TCC.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\CAPE.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\CIN.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\D2M.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\CP.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\AOD_SEA.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\AOD_SUL.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\AOD_NIT.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\AOD_DUST.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\AOD_TOT.json...\n",
      "INFO:root:Data successfully saved.\n",
      "INFO:root:Converting data to dictionary...\n",
      "INFO:root:Rounding numeric values to 2 decimal places...\n",
      "INFO:root:Saving data to e:\\test_climate\\subhrajitjubu.github.io - Copy\\srcc\\TIME.json...\n",
      "INFO:root:Data successfully saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    " dict_l(1e9*pm25,\"PM25\")\n",
    " dict_l(1e9*pm10,\"PM10\")\n",
    "\n",
    " dict_l(lcc,\"LCC\")\n",
    " dict_l(mcc,\"MCC\")\n",
    " dict_l(hcc,\"HCC\")\n",
    " dict_l(tcc,\"TCC\")\n",
    "\n",
    " dict_l(cape,\"CAPE\")\n",
    " dict_l(cin,\"CIN\")\n",
    " dict_l(d2m-273.15,\"D2M\")\n",
    " dict_l(cp*1000,\"CP\")\n",
    "\n",
    " dict_l(aod_ss,\"AOD_SEA\")\n",
    " dict_l(aod_su,\"AOD_SUL\")\n",
    " dict_l(aod_ni,\"AOD_NIT\")\n",
    " dict_l(aod_du,\"AOD_DUST\")\n",
    " dict_l(aod,\"AOD_TOT\")\n",
    "\n",
    "dict_l(time,\"TIME\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
