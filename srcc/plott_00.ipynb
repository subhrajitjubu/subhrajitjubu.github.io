{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi numpy urllib3  pandas datetime xarray[complete] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "# plt.style.available\n",
    "#import colormaps as cmaps \n",
    "#import concurrent\n",
    "import numpy as np\n",
    "# # Libraries to assist with animation and visualisations\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Disable warnings for data download via API\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "# import cfgrib\n",
    "# import eccodes\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "import zipfile\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from zipfile import ZipFile \n",
    "import cdsapi\n",
    "URL = 'https://ads.atmosphere.copernicus.eu/api'\n",
    "KEY = '87bb8d36-2458-48c2-b5e3-f1fd352291bc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def dict_l(data, fm):\n",
    "    try:\n",
    "        # Validate filename\n",
    "       \n",
    "        \n",
    "        # Convert data to dictionary\n",
    "        logging.info(\"Converting data to dictionary...\")\n",
    "        data_dict = data.squeeze().to_dict(data='list', encoding=False)\n",
    "        \n",
    "        # Helper function to recursively round numeric values\n",
    "        def round_numbers(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: round_numbers(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [round_numbers(item) for item in obj]\n",
    "            elif isinstance(obj, (float, np.float32, np.float64)):\n",
    "                return round(float(obj), 2)  # Round floats to 2 decimal places\n",
    "            elif isinstance(obj, (int, np.int32, np.int64)):\n",
    "                return int(obj)  # Keep integers as-is\n",
    "            else:\n",
    "                return obj  # Leave other types unchanged\n",
    "        \n",
    "        # Apply rounding to the dictionary\n",
    "        logging.info(\"Rounding numeric values to 2 decimal places...\")\n",
    "        rounded_data_dict = round_numbers(data_dict)\n",
    "        \n",
    "        # Helper function to handle non-serializable types\n",
    "        def convert_types(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: convert_types(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_types(item) for item in obj]\n",
    "            elif isinstance(obj, (np.datetime64, pd.Timestamp, datetime)):\n",
    "                return obj.isoformat()\n",
    "            elif isinstance(obj, timedelta):\n",
    "                return obj.total_seconds()\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, (np.float32, np.float64)):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, (np.int32, np.int64)):\n",
    "                return int(obj)\n",
    "            raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "        \n",
    "        # Save to JSON file\n",
    "        file = os.path.join(os.getcwd(), f\"{fm}.json\")\n",
    "        logging.info(f\"Saving data to {file}...\")\n",
    "        with open(file, 'w') as json_file:\n",
    "            json.dump(rounded_data_dict, json_file, indent=4, default=convert_types)\n",
    "        \n",
    "        logging.info(\"Data successfully saved.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date,timedelta\n",
    "time1=(date.today()).strftime(\"%Y-%m-%d\")\n",
    "time1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = \"cams-global-atmospheric-composition-forecasts\"\n",
    "lead= [str(i) for i in range(0,73)]\n",
    "\n",
    "request = {\n",
    "    \"date\": [f\"{time1}/{time1}\"],\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"leadtime_hour\": lead,\n",
    "    \"type\": [\"forecast\"],\n",
    "    \"data_format\": \"netcdf_zip\",\n",
    "    \"variable\": [\n",
    "         \"2m_dewpoint_temperature\",\n",
    "        \"dust_aerosol_optical_depth_550nm\",\n",
    "        \"mean_sea_level_pressure\",\n",
    "        \"nitrate_aerosol_optical_depth_550nm\",\n",
    "        \"particulate_matter_2.5um\",\n",
    "        \"particulate_matter_10um\",\n",
    "        \"sea_salt_aerosol_optical_depth_550nm\",\n",
    "        \"sulphate_aerosol_optical_depth_550nm\",\n",
    "        \"total_aerosol_optical_depth_550nm\",\n",
    "        \"total_column_water_vapour\",\n",
    "        \"convective_precipitation\",\n",
    "        \"high_cloud_cover\",\n",
    "        \"low_cloud_cover\",\n",
    "        \"medium_cloud_cover\",\n",
    "        \"total_cloud_cover\",\n",
    "        \"most_unstable_convective_available_potential_energy\",\n",
    "        \"most_unstable_convective_inhibition\"\n",
    "\n",
    "    ],\n",
    "    \"area\": [60, 60, 0, 100]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client(url=URL, key=KEY)\n",
    "client.retrieve(dataset, request).download('test.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"test.zip\", 'r') as zObject: \n",
    "    zObject.extractall(path=\".\")  # Specify a different path for extraction\n",
    "\n",
    "ds1 = xr.open_dataset('data_sfc.nc')  # Update the path to the extracted file\n",
    "os.remove('test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds1.copy(deep=True)\n",
    "# Given information\n",
    "forecast_ref_time = ds['forecast_reference_time'].values\n",
    "hours=len(ds['forecast_period'])  # Number of forecast periods\n",
    "\n",
    "if isinstance(forecast_ref_time, (np.ndarray, xr.DataArray)):\n",
    "    forecast_ref_time = forecast_ref_time.item()  # or forecast_ref_time[0]\n",
    "\n",
    "# Convert to datetime if it's numpy datetime64\n",
    "forecast_ref_time = pd.to_datetime(forecast_ref_time)\n",
    "\n",
    "\n",
    "\n",
    "valid_time = pd.date_range(start=forecast_ref_time,  periods=hours,  # 100 hours = 100 steps\n",
    "    freq='1h'     # '1H' = 1-hour frequency\n",
    ")\n",
    "\n",
    "# Verify the length matches your existing time dimension\n",
    "print(f\"Original time length: {len(ds['forecast_period'])}\")\n",
    "print(f\"New time1 length: {len(valid_time)}\")\n",
    "\n",
    "# Assign the new coordinate to your dataset\n",
    "ds = ds.assign_coords(valid_time=('forecast_period', valid_time))\n",
    "\n",
    "# Now you can filter for JJAS months using the new time coordinate\n",
    "\n",
    "# If you want to make time1 the main dimension coordinate:\n",
    "ds = ds.swap_dims({'forecast_period': 'valid_time'})\n",
    "ds = ds.drop_vars('forecast_period')  # optional - remove the old time coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aod_du=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['duaod550']\n",
    "aod_ss=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['ssaod550']\n",
    "aod_su=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['suaod550']\n",
    "aod=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['aod550']\n",
    "aod_ni=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['niaod550']\n",
    "time=ds.valid_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pm25=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['pm2p5']\n",
    "pm10=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['pm10']\n",
    "\n",
    "lcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['lcc']\n",
    "mcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mcc']\n",
    "hcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['hcc']\n",
    "tcc=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['tcc']\n",
    "\n",
    "cape=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mucape']\n",
    "cin=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['mucin']\n",
    "\n",
    "d2m=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['d2m']\n",
    "cp=ds.sel(longitude=slice(60,100),latitude=slice(40,0))['cp']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " dict_l(1e9*pm25,\"PM25\")\n",
    " dict_l(1e9*pm10,\"PM10\")\n",
    "\n",
    " dict_l(lcc,\"LCC\")\n",
    " dict_l(mcc,\"MCC\")\n",
    " dict_l(hcc,\"HCC\")\n",
    " dict_l(tcc,\"TCC\")\n",
    "\n",
    " dict_l(cape,\"CAPE\")\n",
    " dict_l(cin,\"CIN\")\n",
    " dict_l(d2m-273.15,\"D2M\")\n",
    " dict_l(cp*1000,\"CP\")\n",
    "\n",
    " dict_l(aod_ss,\"AOD_SEA\")\n",
    " dict_l(aod_su,\"AOD_SUL\")\n",
    " dict_l(aod_ni,\"AOD_NIT\")\n",
    " dict_l(aod_du,\"AOD_DUST\")\n",
    " dict_l(aod,\"AOD_TOT\")\n",
    "\n",
    "dict_l(time,\"TIME\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
